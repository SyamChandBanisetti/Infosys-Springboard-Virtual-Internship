{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4091231-bd96-47c3-b01a-7b460eebeff0",
   "metadata": {},
   "source": [
    "# Day 8 — Imputing `Wind_Speed(mph)` and `Weather_Condition`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b097df8-b6f0-4adf-b31d-a5db52b5c2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (7728394, 46)\n"
     ]
    }
   ],
   "source": [
    "# Step — Imports & load dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = r\"D:\\Infosys SpringBoard Virtual Internship 6.0\\US_Accidents_March23.csv\"\n",
    "us_accidents_df = pd.read_csv(dataset_path)\n",
    "print(\"Loaded:\", us_accidents_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9990b7d-84b7-49f6-ba3f-18dc16a0830f",
   "metadata": {},
   "source": [
    "## Step 1 — Quick check of missing values (before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3621b7d9-08da-464b-9f10-7b4a819a4de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing counts (before):\n",
      " Wind_Speed(mph)       571233\n",
      "Precipitation(in)    2203586\n",
      "Weather_Condition     173459\n",
      "dtype: int64\n",
      "\n",
      "Missing % (before):\n",
      " Wind_Speed(mph)       7.391\n",
      "Precipitation(in)    28.513\n",
      "Weather_Condition     2.244\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# show missing counts and percentages for the two columns we target + top few others\n",
    "cols = ['Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition']\n",
    "missing_before = us_accidents_df[cols].isnull().sum()\n",
    "missing_pct_before = (us_accidents_df[cols].isnull().mean() * 100).round(3)\n",
    "print(\"Missing counts (before):\\n\", missing_before)\n",
    "print(\"\\nMissing % (before):\\n\", missing_pct_before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a236d-8ca0-42a1-8a97-b0f64312103b",
   "metadata": {},
   "source": [
    "## Step 2 — (RECOMMENDED for beginners) Simple & safe imputation\n",
    "- `Wind_Speed(mph)` → fill with **median** (robust to outliers).  \n",
    "- `Weather_Condition` → fill with **state-wise mode** (if available), otherwise global mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d466af0f-77c4-46a4-aa83-d8ffb396d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing after simple imputation:\n",
      " Wind_Speed(mph)      0\n",
      "Weather_Condition    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ensure Start_Time -> Hour exists (useful later)\n",
    "us_accidents_df['Start_Time'] = pd.to_datetime(us_accidents_df['Start_Time'], errors='coerce')\n",
    "if 'Hour' not in us_accidents_df.columns:\n",
    "    us_accidents_df['Hour'] = us_accidents_df['Start_Time'].dt.hour\n",
    "\n",
    "# 1) Wind_Speed: fill with median\n",
    "wind_median = us_accidents_df['Wind_Speed(mph)'].median()\n",
    "us_accidents_df['Wind_Speed(mph)'] = us_accidents_df['Wind_Speed(mph)'].fillna(wind_median)\n",
    "\n",
    "# 2) Weather_Condition: try state-wise mode first, then global mode\n",
    "# compute mode per state\n",
    "state_mode = us_accidents_df.groupby('State')['Weather_Condition'] \\\n",
    "            .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "\n",
    "# map state mode to rows and fill\n",
    "us_accidents_df['Weather_Condition'] = us_accidents_df['Weather_Condition'].fillna(\n",
    "    us_accidents_df['State'].map(state_mode)\n",
    ")\n",
    "\n",
    "# fill any remaining with global mode\n",
    "global_mode = us_accidents_df['Weather_Condition'].mode().iloc[0]\n",
    "us_accidents_df['Weather_Condition'] = us_accidents_df['Weather_Condition'].fillna(global_mode)\n",
    "\n",
    "# Confirm missing after simple imputation\n",
    "missing_after_simple = us_accidents_df[['Wind_Speed(mph)', 'Weather_Condition']].isnull().sum()\n",
    "print(\"\\nMissing after simple imputation:\\n\", missing_after_simple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75618b8-382e-4762-b20c-920c9908e74b",
   "metadata": {},
   "source": [
    "## Step 3 — Smarter, scalable numeric imputation (group medians)\n",
    "If you want better numeric estimates without heavy ML, use group medians (e.g., median `Wind_Speed` per `State` and `Hour`), then fall back to overall median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d16f863-0f0b-4a0d-89af-5a8686550237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Wind_Speed before: 0\n",
      "Missing Wind_Speed after group-median imputation (Wind_Speed_imp): 0\n"
     ]
    }
   ],
   "source": [
    "# create a copy (safety) if you want to compare methods\n",
    "df_group_imp = us_accidents_df.copy()\n",
    "\n",
    "# compute median wind speed by State + Hour\n",
    "group_median = df_group_imp.groupby(['State', 'Hour'])['Wind_Speed(mph)'].median()\n",
    "\n",
    "# fill missing using the group median via map on (State,Hour)\n",
    "# create a MultiIndex series for mapping\n",
    "group_median = group_median.rename('grp_med')\n",
    "df_idx = df_group_imp.set_index(['State','Hour'])\n",
    "df_idx['Wind_Speed_imp'] = df_idx['Wind_Speed(mph)'].fillna(group_median)\n",
    "df_group_imp = df_idx.reset_index()\n",
    "\n",
    "# any remaining missing -> fill with overall median\n",
    "overall_median = df_group_imp['Wind_Speed(mph)'].median()\n",
    "df_group_imp['Wind_Speed_imp'] = df_group_imp['Wind_Speed_imp'].fillna(overall_median)\n",
    "\n",
    "# show change counts\n",
    "print(\"Missing Wind_Speed before:\", us_accidents_df['Wind_Speed(mph)'].isnull().sum())\n",
    "print(\"Missing Wind_Speed after group-median imputation (Wind_Speed_imp):\",\n",
    "      df_group_imp['Wind_Speed_imp'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d940319-ab0e-4969-97c1-217da98e2bee",
   "metadata": {},
   "source": [
    "## Step 4 — OPTIONAL: KNN imputation on a sample (advanced / slower)\n",
    "- Use when you want neighbor-based estimates.\n",
    "- **Requires** scikit-learn (`pip install scikit-learn`) and may be slow for large samples.\n",
    "- We'll run KNNImputer on a sampled subset, then write imputed Wind_Speed back for those sampled rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e778846-3656-4fbc-b934-0cff20f10182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After KNN-sample imputation, missing Wind_Speed: 0\n"
     ]
    }
   ],
   "source": [
    "# If scikit-learn isn't installed uncomment and run this in a cell:\n",
    "# !pip install scikit-learn\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Select numeric features that help predict Wind_Speed\n",
    "num_features = ['Wind_Speed(mph)', 'Temperature(F)', 'Visibility(mi)', 'Pressure(in)', 'Humidity(%)', 'Distance(mi)']\n",
    "\n",
    "# sample rows (choose sample size you can handle; 50k-100k is reasonable if memory allows)\n",
    "sample_size = 80000\n",
    "sample_df = us_accidents_df[num_features].sample(n=sample_size, random_state=42)\n",
    "\n",
    "# fit KNN imputer on the sample\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "sample_imputed = knn_imputer.fit_transform(sample_df)\n",
    "\n",
    "# convert back to DataFrame and restore index so we can place results back\n",
    "sample_imputed_df = pd.DataFrame(sample_imputed, columns=sample_df.columns, index=sample_df.index)\n",
    "\n",
    "# put imputed Wind_Speed into main df for sampled rows only\n",
    "us_accidents_df.loc[sample_imputed_df.index, 'Wind_Speed(mph)'] = sample_imputed_df['Wind_Speed(mph)']\n",
    "\n",
    "print(\"After KNN-sample imputation, missing Wind_Speed:\", us_accidents_df['Wind_Speed(mph)'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b298279-f6e3-4afd-b2e7-edb77d313827",
   "metadata": {},
   "source": [
    "## Step 5 — Confirm results, compare methods, and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b60424-80b9-4f22-ae39-9755418c5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final missing counts:\n",
      "Wind_Speed(mph)      0\n",
      "Weather_Condition    0\n",
      "dtype: int64\n",
      "\n",
      "Done — inspect the printed counts above. Save the DataFrame after verifying.\n"
     ]
    }
   ],
   "source": [
    "# Summary of missing for our columns after whatever steps you applied\n",
    "print(\"Final missing counts:\")\n",
    "print(us_accidents_df[['Wind_Speed(mph)', 'Weather_Condition']].isnull().sum())\n",
    "\n",
    "# If you used df_group_imp and want to keep its Wind_Speed_imp column as final:\n",
    "# us_accidents_df['Wind_Speed(mph)'] = df_group_imp['Wind_Speed_imp']  # only if indices align; otherwise merge carefully\n",
    "\n",
    "# Save cleaned smaller sample or the full cleaned dataset (optional)\n",
    "# us_accidents_df.to_csv(r\"D:\\Infosys SpringBoard Virtual Internship 6.0\\US_Accidents_March23_imputed.csv\", index=False)\n",
    "print(\"\\nDone — inspect the printed counts above. Save the DataFrame after verifying.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
