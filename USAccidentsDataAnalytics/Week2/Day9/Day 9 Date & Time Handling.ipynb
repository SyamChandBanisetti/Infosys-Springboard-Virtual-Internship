{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6654a78-3896-45e6-8004-95fe9ab9030b",
   "metadata": {},
   "source": [
    "##  Imports & Create Synthetic Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ee50a9-8b35-49d5-aad1-9ab165bcf962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset with date column as string:\n",
      "   accident_id    date_str  severity\n",
      "0            1  2023-01-07         1\n",
      "1            2  2023-01-04         2\n",
      "2            3  2023-01-08         4\n",
      "3            4  2023-01-05         4\n",
      "4            5  2023-01-07         2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 10 consecutive dates as strings\n",
    "dates = pd.date_range(start='2023-01-01', periods=10, freq='D').astype(str)\n",
    "\n",
    "# Randomly pick 15 dates (with repeats)\n",
    "random_dates = np.random.choice(dates, size=15)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'accident_id': range(1, 16),\n",
    "    'date_str': random_dates,\n",
    "    'severity': np.random.randint(1, 5, size=15)\n",
    "})\n",
    "\n",
    "print(\"Initial dataset with date column as string:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6cfec-b1cd-44c3-9d9c-686886a2d037",
   "metadata": {},
   "source": [
    "## Step 1 — Quick check of datetime column type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9abf8001-47f1-40c0-ba14-7ecbcc37a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column types before conversion:\n",
      "accident_id     int64\n",
      "date_str       object\n",
      "severity        int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Column types before conversion:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470e9b1-89ea-47e1-b1d5-3822e1c70787",
   "metadata": {},
   "source": [
    "## Step 2 — Convert string column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82798cf4-4981-40c2-8881-4d0f93914117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after conversion:\n",
      "   accident_id    date_str  severity       date\n",
      "0            1  2023-01-07         1 2023-01-07\n",
      "1            2  2023-01-04         2 2023-01-04\n",
      "2            3  2023-01-08         4 2023-01-08\n",
      "3            4  2023-01-05         4 2023-01-05\n",
      "4            5  2023-01-07         2 2023-01-07\n",
      "\n",
      "Column types after conversion:\n",
      "accident_id             int64\n",
      "date_str               object\n",
      "severity                int32\n",
      "date           datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date_str'], errors='coerce')\n",
    "\n",
    "print(\"\\nDataset after conversion:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn types after conversion:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d87b2-29b4-4139-a0f6-6f2649068a9d",
   "metadata": {},
   "source": [
    "## Step 3 — Extract datetime features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee1ae44-77c2-485e-8022-fbf70dc5022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset with extracted datetime features:\n",
      "   accident_id    date_str  severity       date  hour    weekday    month\n",
      "0            1  2023-01-07         1 2023-01-07     0   Saturday  January\n",
      "1            2  2023-01-04         2 2023-01-04     0  Wednesday  January\n",
      "2            3  2023-01-08         4 2023-01-08     0     Sunday  January\n",
      "3            4  2023-01-05         4 2023-01-05     0   Thursday  January\n",
      "4            5  2023-01-07         2 2023-01-07     0   Saturday  January\n"
     ]
    }
   ],
   "source": [
    "df['hour'] = df['date'].dt.hour             # Hour of the day\n",
    "df['weekday'] = df['date'].dt.day_name()   # Day of the week name\n",
    "df['month'] = df['date'].dt.month_name()   # Month name\n",
    "\n",
    "print(\"\\nDataset with extracted datetime features:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c7a42-2878-45e9-a2ab-0dfc9efc4dc3",
   "metadata": {},
   "source": [
    "## Step 4 — Introduce missing datetime values (NaT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4284a2a-75dc-4a65-864f-9e355de67ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset with missing datetime values (NaT):\n",
      "   accident_id    date_str  severity date  hour    weekday    month\n",
      "1            2  2023-01-04         2  NaT     0  Wednesday  January\n",
      "5            6  2023-01-10         2  NaT     0    Tuesday  January\n"
     ]
    }
   ],
   "source": [
    "# Randomly set 2 rows to NaT\n",
    "nan_indices = np.random.choice(df.index, size=2, replace=False)\n",
    "df.loc[nan_indices, 'date'] = pd.NaT\n",
    "\n",
    "print(\"\\nDataset with missing datetime values (NaT):\")\n",
    "print(df.loc[nan_indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbecd32-6688-4843-af24-a5fd7fa2e48c",
   "metadata": {},
   "source": [
    "## Step 5 — Fill missing datetime values (Forward Fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d464d962-3b12-49fb-b2f4-d2a23614c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after filling missing datetime values (forward fill):\n",
      "   accident_id    date_str  severity date  hour    weekday    month  \\\n",
      "1            2  2023-01-04         2  NaT     0  Wednesday  January   \n",
      "5            6  2023-01-10         2  NaT     0    Tuesday  January   \n",
      "\n",
      "  date_filled  \n",
      "1  2023-01-07  \n",
      "5  2023-01-07  \n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing datetime values\n",
    "df['date_filled'] = df['date'].ffill()\n",
    "\n",
    "print(\"\\nDataset after filling missing datetime values (forward fill):\")\n",
    "print(df.loc[nan_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ac5445-9dc3-4c6e-b0b7-eac9561a936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows after dropping missing datetime:\n",
      "   accident_id    date_str  severity       date  hour   weekday    month  \\\n",
      "0            1  2023-01-07         1 2023-01-07     0  Saturday  January   \n",
      "2            3  2023-01-08         4 2023-01-08     0    Sunday  January   \n",
      "3            4  2023-01-05         4 2023-01-05     0  Thursday  January   \n",
      "4            5  2023-01-07         2 2023-01-07     0  Saturday  January   \n",
      "6            7  2023-01-03         2 2023-01-03     0   Tuesday  January   \n",
      "\n",
      "  date_filled  \n",
      "0  2023-01-07  \n",
      "2  2023-01-08  \n",
      "3  2023-01-05  \n",
      "4  2023-01-07  \n",
      "6  2023-01-03  \n"
     ]
    }
   ],
   "source": [
    "df_dropped = df.dropna(subset=['date'])\n",
    "print(\"\\nRows after dropping missing datetime:\")\n",
    "print(df_dropped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d98d683-4ebd-4917-a680-a68ce3bf30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with date after 2023-01-05:\n",
      "   accident_id    date_str  severity       date  hour   weekday    month  \\\n",
      "0            1  2023-01-07         1 2023-01-07     0  Saturday  January   \n",
      "2            3  2023-01-08         4 2023-01-08     0    Sunday  January   \n",
      "4            5  2023-01-07         2 2023-01-07     0  Saturday  January   \n",
      "7            8  2023-01-07         4 2023-01-07     0  Saturday  January   \n",
      "8            9  2023-01-08         4 2023-01-08     0    Sunday  January   \n",
      "\n",
      "  date_filled  \n",
      "0  2023-01-07  \n",
      "2  2023-01-08  \n",
      "4  2023-01-07  \n",
      "7  2023-01-07  \n",
      "8  2023-01-08  \n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[df['date'] > pd.Timestamp('2023-01-05')]\n",
    "print(\"\\nRows with date after 2023-01-05:\")\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e25e48-faca-4340-894c-c298b9c500dd",
   "metadata": {},
   "source": [
    "## Step 6 — Quick summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963231b5-8562-4c5a-a9ef-362f07b3793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing datetime values (original): 2\n",
      "Missing datetime values (after fill): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing datetime values (original):\", df['date'].isnull().sum())\n",
    "print(\"Missing datetime values (after fill):\", df['date_filled'].isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
